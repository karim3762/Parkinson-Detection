{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m3Q3CHkUkNS"
      },
      "outputs": [],
      "source": [
        "#  KNN\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# # read dataset 1\n",
        "# data=pd.read_csv('/content/Parkinsson disease.csv')\n",
        "# # replace zeros\n",
        "\n",
        "# read dataset 2\n",
        "data=pd.read_csv('/content/pd.csv')\n",
        "# replace zeros\n",
        "\n",
        "#split the dataset\n",
        "X=data.drop(['status','name'],axis=1)\n",
        "Y=data['status']\n",
        "\n",
        "\n",
        "# X,Y=make_classification(n_samples= 200,n_features=8,n_informative=8,n_redundant=0,n_repeated=0,n_classes=2,random_state=14)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state=0,shuffle=True)\n",
        "# print(X)\n",
        "# print (y)\n",
        "\n",
        "#feature scalling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "# define the classifier\n",
        "# print(math.sqrt(len(y_test)))\n",
        "knn = KNeighborsClassifier(n_neighbors=5,p=2,metric='euclidean')\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "# prediction\n",
        "y_pred= knn.predict(X_test)\n",
        "# evaluate\n",
        "accuracy=round(int(metrics.accuracy_score(y_test,y_pred)*100),2)\n",
        "precision =round( metrics.precision_score(y_test, y_pred)*100,2)\n",
        "recall = round(metrics.recall_score(y_test, y_pred)*100,2)\n",
        "print(\"Precision:\", precision,\"%\")\n",
        "print(\"Recall:\", recall,\"%\")\n",
        "print(\"Accuracy is\",accuracy,\"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "# # read dataset 1\n",
        "# data=pd.read_csv('/content/Parkinsson disease.csv')\n",
        "# # replace zeros\n",
        "\n",
        "# read dataset 2\n",
        "data=pd.read_csv('/content/pd_speech_features.csv')\n",
        "# replace zeros\n",
        "\n",
        "#split the dataset\n",
        "X=data.drop(['status','name'],axis=1)\n",
        "Y=data['status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state=42,shuffle=True)\n",
        "\n",
        "#feature scalling \n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# define the classifier\n",
        "svc=SVC(C=.1,kernel='linear', gamma= 1)\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "# prediction\n",
        "y_pred = svc .predict(X_test)\n",
        "\n",
        "# evaluate\n",
        "accuracy=round(int(metrics.accuracy_score(y_test,y_pred)*100),2)\n",
        "precision =round( metrics.precision_score(y_test, y_pred)*100,2)\n",
        "recall = round(metrics.recall_score(y_test, y_pred)*100,2)\n",
        "print(\"Precision:\", precision,\"%\")\n",
        "print(\"Recall:\", recall,\"%\")\n",
        "print(\"Accuracy is\",accuracy,\"%\")\n"
      ],
      "metadata": {
        "id": "dLdct8tfvhJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# # read dataset 1\n",
        "# data=pd.read_csv('/content/Parkinsson disease.csv')\n",
        "# # replace zeros\n",
        "\n",
        "# read dataset 2\n",
        "data=pd.read_csv('/content/pd_speech_features.csv')\n",
        "# replace zeros\n",
        "\n",
        "#split the dataset\n",
        "X=data.drop(['status','name'],axis=1)\n",
        "Y=data['status']\n",
        "\n",
        "# X,Y=make_classification(n_samples= 200,n_features=40,n_informative=8,n_redundant=0,n_repeated=0,n_classes=2,random_state=14)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state=0,shuffle=True)\n",
        "\n",
        "#feature scalling \n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# define the classifier\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train,y_train)\n",
        "\n",
        "# prediction\n",
        "y_pred=dtree.predict(X_test)\n",
        "# evaluate\n",
        "accuracy=round(int(metrics.accuracy_score(y_test,y_pred)*100),2)\n",
        "precision =round( metrics.precision_score(y_test, y_pred)*100,2)\n",
        "recall = round(metrics.recall_score(y_test, y_pred)*100,2)\n",
        "print(\"Precision:\", precision,\"%\")\n",
        "print(\"Recall:\", recall,\"%\")\n",
        "print(\"Accuracy is\",accuracy,\"%\")\n"
      ],
      "metadata": {
        "id": "BGToh6uDvYTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code random forest 27/12 karim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# # read dataset 1\n",
        "# data=pd.read_csv('/content/Parkinsson disease.csv')\n",
        "# # replace zeros\n",
        "\n",
        "# read dataset 2\n",
        "data=pd.read_csv('/content/pd_speech_features.csv')\n",
        "# replace zeros\n",
        "\n",
        "#split the dataset\n",
        "X=data.drop(['status','name'],axis=1)\n",
        "Y=data['status']\n",
        "\n",
        "# X,Y=make_classification(n_samples= 200,n_features=8,n_informative=8,n_redundant=0,n_repeated=0,n_classes=2,random_state=14)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state=0,shuffle=True)\n",
        "# print(X)\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0,random_state=0, shuffle=False)\n",
        "rf_model = RandomForestClassifier(n_estimators=50, max_features=\"auto\", random_state=44)\n",
        "rf_model.fit(X_train, y_train)\n",
        "# prediction\n",
        "y_pred= rf_model.predict(X_test)\n",
        "# evaluate\n",
        "accuracy=round(int(metrics.accuracy_score(y_test,y_pred)*100),2)\n",
        "precision =round( metrics.precision_score(y_test, y_pred)*100,2)\n",
        "recall = round(metrics.recall_score(y_test, y_pred)*100,2)\n",
        "print(\"Precision:\", precision,\"%\")\n",
        "print(\"Recall:\", recall,\"%\")\n",
        "print(\"Accuracy is\",accuracy,\"%\")\n"
      ],
      "metadata": {
        "id": "Ma6splV0VPGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code Naive Bayes \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# # read dataset 1\n",
        "# data=pd.read_csv('/content/Parkinsson disease.csv')\n",
        "# # replace zeros\n",
        "\n",
        "# read dataset 2\n",
        "data=pd.read_csv('/content/pd_speech_features.csv')\n",
        "# replace zeros\n",
        "\n",
        "#split the dataset\n",
        "X=data.drop(['status','name'],axis=1)\n",
        "Y=data['status']\n",
        "\n",
        "# X,Y=make_classification(n_samples= 200,n_features=40,n_informative=8,n_redundant=0,n_repeated=0,n_classes=2,random_state=14)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state=100,shuffle=True)\n",
        "\n",
        "#feature scalling \n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# define the classifier\n",
        "model = GaussianNB()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# prediction\n",
        "y_pred=model.predict(X_test)\n",
        "# evaluate\n",
        "accuracy=round(int(metrics.accuracy_score(y_test,y_pred)*100),2)\n",
        "precision =round( metrics.precision_score(y_test, y_pred)*100,2)\n",
        "recall = round(metrics.recall_score(y_test, y_pred)*100,2)\n",
        "print(\"Precision:\", precision,\"%\")\n",
        "print(\"Recall:\", recall,\"%\")\n",
        "print(\"Accuracy is\",accuracy,\"%\")"
      ],
      "metadata": {
        "id": "yhB-Y2ZplY4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6fVpWnBfy5z4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}